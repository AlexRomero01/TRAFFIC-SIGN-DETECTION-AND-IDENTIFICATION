{"cells":[{"cell_type":"markdown","metadata":{"id":"JGsQE5slndXB"},"source":["# Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bYFNAST9WUg_"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import cv2\n","import tensorflow as tf\n","from PIL import Image\n","import os\n","import keras\n","from sklearn.model_selection import train_test_split\n","from keras.utils import to_categorical\n","from keras.models import Sequential, load_model\n","from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n","from google.colab import drive\n","from matplotlib import style\n","import random\n","style.use('fivethirtyeight')\n","\n","\n","\n","from tensorflow import keras\n","from PIL import Image\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.metrics import accuracy_score\n","np.random.seed(42)"]},{"cell_type":"markdown","metadata":{"id":"MhKHoXHQnn7A"},"source":["# Data storage"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":64036,"status":"ok","timestamp":1713951241645,"user":{"displayName":"Àlex Romero Segués","userId":"08771803099075012026"},"user_tz":-120},"id":"P64PhmuWvNb5","outputId":"865e5984-8faa-405f-ab82-fef133acb7fe"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["# Montar Google Drive\n","drive.mount('/content/drive')\n","dataset_path = '/content/drive/MyDrive/TFG CODE/DATASET IDENTIFIER/'\n","os.chdir = dataset_path"]},{"cell_type":"markdown","metadata":{"id":"An-ayQPr15rd"},"source":["Useful paths for later on"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ikBexNlV129n"},"outputs":[],"source":["train_path = '/content/drive/MyDrive/TFG CODE/DATASET IDENTIFIER/Train'\n","test_path = '/content/drive/MyDrive/TFG CODE/DATASET IDENTIFIER/Test'\n","data_dir = '/content/drive/MyDrive/TFG CODE/DATASET IDENTIFIER'\n","\n","IMG_HEIGHT = 30\n","IMG_WIDTH = 30\n","channels = 3"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IzqwpHS_z4rf"},"outputs":[],"source":["NUM_CATEGORIES = len(os.listdir(train_path))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fXo2PpskZ6FO"},"outputs":[],"source":["data = []\n","labels = []\n","# We have 43 different kinds of signals\n","classes = 2\n","cur_path = os.getcwd()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K9Dgs5LvxIX4"},"outputs":[],"source":["class_names = { 0:'No signal)', 1:'Signal' }"]},{"cell_type":"markdown","metadata":{"id":"LcTX2axypVdx"},"source":["# Data processing\n"]},{"cell_type":"markdown","metadata":{"id":"dalweAJ0peUm"},"source":["Very important part. A loop that checks all the data inside the train folder and labels it correctly and stores everything in each list (data and labels) created before. 1 by 1 it resizes the image to 30x30 pixels so later we will have no problems when training the AI with these images."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1114520,"status":"ok","timestamp":1713952357107,"user":{"displayName":"Àlex Romero Segués","userId":"08771803099075012026"},"user_tz":-120},"id":"6tNyeSr2ZJyd","outputId":"a26e71b4-e3b5-4f2f-99fa-edf2edcbeee0"},"outputs":[{"name":"stdout","output_type":"stream","text":["cannot identify image file '/content/drive/MyDrive/TFG CODE/DATASET IDENTIFIER/Train/1/GT-final_test.csv'\n"]}],"source":["for i in range(classes):\n","    path = os.path.join(dataset_path, 'Train', str(i))\n","    images = os.listdir(path)\n","    for a in images:\n","        try:\n","            image = Image.open(os.path.join(path, a))\n","            image = image.resize((IMG_HEIGHT, IMG_WIDTH))\n","            image = np.array(image)\n","            data.append(image)\n","            labels.append(i)\n","        except Exception as e:\n","            print(e)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I6f6gaFHotHw"},"outputs":[],"source":["# Convertir listas a numpy arrays\n","data = np.array(data)\n","labels = np.array(labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31,"status":"ok","timestamp":1713952357114,"user":{"displayName":"Àlex Romero Segués","userId":"08771803099075012026"},"user_tz":-120},"id":"CHSRENhOoBTQ","outputId":"eb0a04e8-e0eb-43d7-a0e3-80a19b6cfe91"},"outputs":[{"name":"stdout","output_type":"stream","text":["(24630, 30, 30, 3) (24630,)\n"]}],"source":["print(data.shape, labels.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kcOXc60Wnyn3"},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1713952357513,"user":{"displayName":"Àlex Romero Segués","userId":"08771803099075012026"},"user_tz":-120},"id":"4zri1HG6uTFS","outputId":"2443a1a7-9309-4b8b-f5d9-3908642ac48d"},"outputs":[{"name":"stdout","output_type":"stream","text":["(19704, 30, 30, 3) (4926, 30, 30, 3) (19704,) (4926,)\n"]}],"source":["print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u7zfWVHawr1J"},"outputs":[],"source":["y_train = to_categorical(y_train, 43)\n","y_test = to_categorical(y_test, 43)"]},{"cell_type":"markdown","metadata":{"id":"iKV1TEyzjcbU"},"source":["Splitting the data into train and validation set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WTHyKs384IIr"},"outputs":[],"source":["shuffle_indexes = np.arange(data.shape[0])\n","np.random.shuffle(shuffle_indexes)\n","data = data[shuffle_indexes]\n","labels = labels[shuffle_indexes]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":339,"status":"ok","timestamp":1713952357835,"user":{"displayName":"Àlex Romero Segués","userId":"08771803099075012026"},"user_tz":-120},"id":"f0UCUVZmjbf9","outputId":"b780b244-d3c6-4344-de3c-1436c2d7dfe2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Random:  4281\n","X_train.shape (17241, 30, 30, 3)\n","X_valid.shape (7389, 30, 30, 3)\n","y_train.shape (17241,)\n","y_valid.shape (7389,)\n"]}],"source":["random_state=random.randint(1,10000)\n","X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.3, random_state=42, shuffle=True)   #random.randint(1,10000)\n","\n","X_train = X_train/255\n","X_val = X_val/255\n","\n","print(\"Random: \", random_state)\n","print(\"X_train.shape\", X_train.shape)\n","print(\"X_valid.shape\", X_val.shape)\n","print(\"y_train.shape\", y_train.shape)\n","print(\"y_valid.shape\", y_val.shape)"]},{"cell_type":"markdown","metadata":{"id":"k0PDpqMhizco"},"source":["One hot encoding the labels"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31,"status":"ok","timestamp":1713952357836,"user":{"displayName":"Àlex Romero Segués","userId":"08771803099075012026"},"user_tz":-120},"id":"zlRdShvpixgO","outputId":"6df24e37-b083-4085-829b-ea9554d58ff2"},"outputs":[{"name":"stdout","output_type":"stream","text":["(17241, 2)\n","(7389, 2)\n"]}],"source":["y_train = keras.utils.to_categorical(y_train, classes)\n","y_val = keras.utils.to_categorical(y_val, classes)\n","\n","print(y_train.shape)\n","print(y_val.shape)"]},{"cell_type":"markdown","metadata":{"id":"Mj6ZlUsdpaI3"},"source":["# Model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10489,"status":"ok","timestamp":1713952368295,"user":{"displayName":"Àlex Romero Segués","userId":"08771803099075012026"},"user_tz":-120},"id":"SdaTdvx4hCfJ","outputId":"688f7a32-3d60-4c21-a2ae-86de95fa2ad5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting keras-tuner\n","  Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m122.9/129.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.15.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (24.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.31.0)\n","Collecting kt-legacy (from keras-tuner)\n","  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2024.2.2)\n","Installing collected packages: kt-legacy, keras-tuner\n","Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"]}],"source":["!pip install keras-tuner\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cv9XmXXKcDNw"},"outputs":[],"source":["aug = ImageDataGenerator(\n","    rotation_range=10,\n","    zoom_range=0.15,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    shear_range=0.15,\n","    horizontal_flip=False,\n","    vertical_flip=False,\n","    fill_mode=\"nearest\")\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MUGnJvl8likg","executionInfo":{"status":"ok","timestamp":1713974585702,"user_tz":-120,"elapsed":427517,"user":{"displayName":"Àlex Romero Segués","userId":"08771803099075012026"}},"outputId":"ec39734f-e613-4520-f1d3-c54c9a3ec014"},"outputs":[{"output_type":"stream","name":"stdout","text":["Trial 30 Complete [00h 22m 40s]\n","val_accuracy: 0.9975639581680298\n","\n","Best val_accuracy So Far: 0.9978346228599548\n","Total elapsed time: 06h 10m 17s\n","The optimal number of filters in the first Conv2D layer is 32\n","The optimal number of filters in the second Conv2D layer is 32\n","The optimal learning rate for the optimizer is 0.0001\n","The optimal number of units in the Dense layer is 768\n"]}],"source":["import kerastuner as kt\n","\n","def model_builder(hp):\n","\n","    model = keras.Sequential()\n","\n","    hp_filters1 = hp.Int('filters1', min_value=16, max_value=128, step=16)\n","    model.add(keras.layers.Conv2D(filters=hp_filters1, kernel_size=(3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, channels)))\n","\n","    hp_filters2 = hp.Int('filters2', min_value=32, max_value=256, step=32)\n","    model.add(keras.layers.Conv2D(filters=hp_filters2, kernel_size=(3, 3), activation='relu'))\n","\n","    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n","\n","    model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n","    model.add(keras.layers.BatchNormalization(axis=-1))\n","\n","    model.add(keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n","    model.add(keras.layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu'))\n","    model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n","    model.add(keras.layers.BatchNormalization(axis=-1))\n","    model.add(keras.layers.Flatten())\n","\n","    hp_units = hp.Int('units', min_value=256, max_value=1024, step=256)\n","    model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n","    model.add(keras.layers.BatchNormalization())\n","    model.add(keras.layers.Dropout(rate=0.5))\n","    model.add(keras.layers.Dense(2, activation='softmax'))\n","\n","    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n","                  loss='categorical_crossentropy',\n","                  metrics=['accuracy'])\n","\n","    return model\n","\n","\n","tuner = kt.Hyperband(model_builder,\n","                     objective='val_accuracy',\n","                     max_epochs=10,\n","\n","                     factor=3,\n","                     directory='my_dir',\n","                     project_name='traffic_sign_recognition')\n","\n","stop_early = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n","\n","tuner.search(aug.flow(X_train, y_train, batch_size=32),\n","             epochs=30,\n","             validation_data=(X_val, y_val),\n","             callbacks=[stop_early])\n","\n","best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n","\n","print(f\"The optimal number of filters in the first Conv2D layer is {best_hps.get('filters1')}\")\n","print(f\"The optimal number of filters in the second Conv2D layer is {best_hps.get('filters2')}\")\n","print(f\"The optimal learning rate for the optimizer is {best_hps.get('learning_rate')}\")\n","print(f\"The optimal number of units in the Dense layer is {best_hps.get('units')}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KXZVqOrZhgnx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713978750889,"user_tz":-120,"elapsed":1468118,"user":{"displayName":"Àlex Romero Segués","userId":"08771803099075012026"}},"outputId":"1a42f287-b7e1-4195-be96-1c7c6bee8770"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","539/539 [==============================] - 89s 161ms/step - loss: 0.2703 - accuracy: 0.9010 - val_loss: 0.6500 - val_accuracy: 0.7402\n","Epoch 2/30\n","539/539 [==============================] - 97s 181ms/step - loss: 0.1285 - accuracy: 0.9544 - val_loss: 0.0633 - val_accuracy: 0.9750\n","Epoch 3/30\n","539/539 [==============================] - 85s 157ms/step - loss: 0.0872 - accuracy: 0.9693 - val_loss: 0.0219 - val_accuracy: 0.9917\n","Epoch 4/30\n","539/539 [==============================] - 86s 160ms/step - loss: 0.0710 - accuracy: 0.9742 - val_loss: 0.0296 - val_accuracy: 0.9907\n","Epoch 5/30\n","539/539 [==============================] - 86s 159ms/step - loss: 0.0537 - accuracy: 0.9821 - val_loss: 0.0120 - val_accuracy: 0.9961\n","Epoch 6/30\n","539/539 [==============================] - 84s 156ms/step - loss: 0.0543 - accuracy: 0.9822 - val_loss: 0.0207 - val_accuracy: 0.9926\n","Epoch 7/30\n","539/539 [==============================] - 86s 160ms/step - loss: 0.0351 - accuracy: 0.9885 - val_loss: 0.0114 - val_accuracy: 0.9970\n","Epoch 8/30\n","539/539 [==============================] - 85s 158ms/step - loss: 0.0390 - accuracy: 0.9859 - val_loss: 0.0097 - val_accuracy: 0.9974\n","Epoch 9/30\n","539/539 [==============================] - 85s 158ms/step - loss: 0.0349 - accuracy: 0.9881 - val_loss: 0.0187 - val_accuracy: 0.9932\n","Epoch 10/30\n","539/539 [==============================] - 83s 153ms/step - loss: 0.0286 - accuracy: 0.9898 - val_loss: 0.0080 - val_accuracy: 0.9970\n","Epoch 11/30\n","539/539 [==============================] - 84s 156ms/step - loss: 0.0277 - accuracy: 0.9904 - val_loss: 0.0145 - val_accuracy: 0.9953\n","Epoch 12/30\n","539/539 [==============================] - 89s 165ms/step - loss: 0.0264 - accuracy: 0.9911 - val_loss: 0.0085 - val_accuracy: 0.9977\n","Epoch 13/30\n","539/539 [==============================] - 86s 160ms/step - loss: 0.0220 - accuracy: 0.9922 - val_loss: 0.0177 - val_accuracy: 0.9940\n","Epoch 14/30\n","539/539 [==============================] - 87s 161ms/step - loss: 0.0256 - accuracy: 0.9903 - val_loss: 0.0158 - val_accuracy: 0.9953\n","Epoch 15/30\n","539/539 [==============================] - 82s 151ms/step - loss: 0.0176 - accuracy: 0.9941 - val_loss: 0.0077 - val_accuracy: 0.9972\n","Epoch 16/30\n","539/539 [==============================] - 83s 154ms/step - loss: 0.0210 - accuracy: 0.9936 - val_loss: 0.1672 - val_accuracy: 0.9603\n","Epoch 17/30\n","539/539 [==============================] - 89s 164ms/step - loss: 0.0171 - accuracy: 0.9945 - val_loss: 0.0084 - val_accuracy: 0.9977\n","Epoch 18/30\n","539/539 [==============================] - 82s 151ms/step - loss: 0.0187 - accuracy: 0.9937 - val_loss: 0.0070 - val_accuracy: 0.9978\n","Epoch 19/30\n","539/539 [==============================] - 89s 165ms/step - loss: 0.0133 - accuracy: 0.9948 - val_loss: 0.0076 - val_accuracy: 0.9980\n","Epoch 20/30\n","539/539 [==============================] - 82s 152ms/step - loss: 0.0136 - accuracy: 0.9952 - val_loss: 0.0084 - val_accuracy: 0.9973\n","Epoch 21/30\n","539/539 [==============================] - 85s 158ms/step - loss: 0.0110 - accuracy: 0.9962 - val_loss: 0.0064 - val_accuracy: 0.9978\n","Epoch 22/30\n","539/539 [==============================] - 89s 165ms/step - loss: 0.0133 - accuracy: 0.9952 - val_loss: 0.0059 - val_accuracy: 0.9984\n","Epoch 23/30\n","539/539 [==============================] - 87s 162ms/step - loss: 0.0123 - accuracy: 0.9954 - val_loss: 0.0335 - val_accuracy: 0.9926\n","Epoch 24/30\n","539/539 [==============================] - 84s 156ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.0054 - val_accuracy: 0.9980\n","Epoch 25/30\n","539/539 [==============================] - 85s 158ms/step - loss: 0.0143 - accuracy: 0.9952 - val_loss: 0.0106 - val_accuracy: 0.9963\n","Epoch 26/30\n","539/539 [==============================] - 87s 161ms/step - loss: 0.0116 - accuracy: 0.9957 - val_loss: 0.0095 - val_accuracy: 0.9966\n","Epoch 27/30\n","539/539 [==============================] - 87s 161ms/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 0.0036 - val_accuracy: 0.9992\n","Epoch 28/30\n","539/539 [==============================] - 82s 153ms/step - loss: 0.0092 - accuracy: 0.9970 - val_loss: 0.0079 - val_accuracy: 0.9976\n","Epoch 29/30\n","539/539 [==============================] - 83s 155ms/step - loss: 0.0120 - accuracy: 0.9959 - val_loss: 0.0050 - val_accuracy: 0.9988\n","Epoch 30/30\n","539/539 [==============================] - 89s 166ms/step - loss: 0.0093 - accuracy: 0.9968 - val_loss: 0.0077 - val_accuracy: 0.9977\n"]}],"source":["# Build the model with the optimal hyperparameters and train it\n","\n","model = tuner.hypermodel.build(best_hps)\n","history = model.fit(aug.flow(X_train, y_train, batch_size=32),\n","                    epochs=30,\n","                    validation_data=(X_val, y_val))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dUHUspKWTUot"},"outputs":[],"source":["save_path = '/content/drive/MyDrive/TFG CODE/model_identifier.h5'\n","model.save(save_path)"]},{"cell_type":"markdown","metadata":{"id":"zcIGXW8IqdXA"},"source":["# Results\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5xF9x7D6mWXP"},"outputs":[],"source":["acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs_range = range(epochs)\n","\n","plt.figure(figsize=(10, 10))\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs_range, acc, label='Training Accuracy')\n","plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation Accuracy')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs_range, loss, label='Training Loss')\n","plt.plot(epochs_range, val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IYarc9REOqPz"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import cv2\n","from PIL import Image\n","from sklearn.metrics import accuracy_score\n","\n","# Assuming you have already defined IMG_HEIGHT, IMG_WIDTH, data_dir, and model\n","\n","# Load the test data\n","test = pd.read_csv(data_dir + '/Test.csv')\n","\n","labels = test[\"classID\"].values\n","imgs = test[\"path\"].values\n","\n","data = []\n","\n","for img in imgs:\n","    try:\n","        image = cv2.imread(data_dir + '/Test/' + img)\n","        if image is None:\n","            print(\"Error in \" + img + \": Image not found or unable to read\")\n","            continue\n","        image_fromarray = Image.fromarray(image, 'RGB')\n","        resize_image = image_fromarray.resize((IMG_HEIGHT, IMG_WIDTH))\n","        data.append(np.array(resize_image))\n","    except Exception as e:\n","        print(\"Error in \" + img + \": \" + str(e))\n","\n","# Preprocess the data\n","X_test = np.array(data)\n","X_test = X_test / 255.0\n","\n","# Make predictions\n","pred_probs = model.predict(X_test)\n","pred = np.argmax(pred_probs, axis=1)\n","\n","# Calculate accuracy\n","print('Test Data accuracy: ', accuracy_score(labels, pred) * 100)"]},{"cell_type":"code","source":["from sklearn.metrics import classification_report\n","print(classification_report(labels, pred))"],"metadata":{"id":"yvyQH29bMYkQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import random\n","\n","plt.figure(figsize=(25, 25))\n","\n","# Randomly select 25 indices from the test dataset\n","random_indices = random.sample(range(len(X_test)), 25)\n","\n","for i, idx in enumerate(random_indices):\n","    plt.subplot(5, 5, i + 1)\n","    plt.grid(False)\n","    plt.xticks([])\n","    plt.yticks([])\n","\n","    # Get the predicted and actual labels for the current sample\n","    prediction = np.argmax(pred[idx])  # Convert probabilities to class labels\n","    actual = labels[idx]\n","\n","    # Set the color based on whether the prediction matches the actual label\n","    col = 'g' if prediction == actual else 'r'\n","\n","    actual_label = classes[actual]\n","    pred_label = classes[prediction]\n","    plt.xlabel('Actual={}\\n({})\\nPred={}\\n({})'.format(actual, actual_label, prediction, pred_label), color=col)\n","    plt.imshow(X_test[idx])\n","\n","# Adjust the spacing between subplots\n","plt.subplots_adjust(hspace=0.5, wspace=0.3)\n","\n","plt.show()\n"],"metadata":{"id":"z-p_Ygm3MdAH"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":["JGsQE5slndXB","MhKHoXHQnn7A","LcTX2axypVdx","Mj6ZlUsdpaI3"],"provenance":[{"file_id":"1AXPq8A3C7JvUVWZUIgwBSQTATNVhU1Mp","timestamp":1713710263964}],"mount_file_id":"1AXPq8A3C7JvUVWZUIgwBSQTATNVhU1Mp","authorship_tag":"ABX9TyMw8TQZ3GrQRKJzqQ+lfcJW"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}