{"cells":[{"cell_type":"code","source":["!git config --global user.name \"AlexRomero01\"\n","!git config --global user.email \"alexromerosegues@gmail.com\"\n","!git clone https://github.com/AlexRomero01/TRAFFIC-SIGN-DETECTION-AND-IDENTIFICATION.git\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JsHrKfSSNZJI","executionInfo":{"status":"ok","timestamp":1717403352786,"user_tz":-120,"elapsed":915,"user":{"displayName":"Àlex Romero Segués","userId":"08771803099075012026"}},"outputId":"7f64b0cd-bae2-4895-e478-a98bd7a4a868"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'TRAFFIC-SIGN-DETECTION-AND-IDENTIFICATION'...\n","warning: You appear to have cloned an empty repository.\n"]}]},{"cell_type":"markdown","metadata":{"id":"JGsQE5slndXB"},"source":["# Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bYFNAST9WUg_"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import cv2\n","import tensorflow as tf\n","from PIL import Image\n","import os\n","import keras\n","from sklearn.model_selection import train_test_split\n","from keras.utils import to_categorical\n","from keras.models import Sequential, load_model\n","from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n","from google.colab import drive\n","from matplotlib import style\n","import random\n","style.use('fivethirtyeight')\n","\n","\n","\n","from tensorflow import keras\n","from PIL import Image\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.metrics import accuracy_score\n","np.random.seed(42)"]},{"cell_type":"markdown","metadata":{"id":"MhKHoXHQnn7A"},"source":["# Data storage"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10874,"status":"ok","timestamp":1715426368452,"user":{"displayName":"Àlex Romero Segués","userId":"08771803099075012026"},"user_tz":-120},"id":"P64PhmuWvNb5","outputId":"7df7f1a9-30bd-4f03-e7ce-aa15c1b9783d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# Montar Google Drive\n","drive.mount('/content/drive')\n","dataset_path = '/content/drive/MyDrive/TFG CODE/DATASET SIGNALS'\n","os.chdir = dataset_path\n","\n","train_path = '/content/drive/MyDrive/TFG CODE/DATASET SIGNALS/Train'\n","test_path = '/content/drive/MyDrive/TFG CODE/DATASET SIGNALS/Test'\n","data_dir = '/content/drive/MyDrive/TFG CODE/DATASET SIGNALS'\n","\n","IMG_HEIGHT = 30\n","IMG_WIDTH = 30\n","channels = 3\n","\n","NUM_CATEGORIES = len(os.listdir(train_path))\n","data = []\n","labels = []\n","# We have 43 different kinds of signals\n","classes = 43\n","cur_path = os.getcwd()"]},{"cell_type":"markdown","metadata":{"id":"An-ayQPr15rd"},"source":["Useful paths for later on"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K9Dgs5LvxIX4"},"outputs":[],"source":["class_names = { 0:'Speed limit (20km/h)',\n","            1:'Speed limit (30km/h)',\n","            2:'Speed limit (50km/h)',\n","            3:'Speed limit (60km/h)',\n","            4:'Speed limit (70km/h)',\n","            5:'Speed limit (80km/h)',\n","            6:'End of speed limit (80km/h)',\n","            7:'Speed limit (100km/h)',\n","            8:'Speed limit (120km/h)',\n","            9:'No passing',\n","            10:'No passing veh over 3.5 tons',\n","            11:'Right-of-way at intersection',\n","            12:'Priority road',\n","            13:'Yield',\n","            14:'Stop',\n","            15:'No vehicles',\n","            16:'Veh > 3.5 tons prohibited',\n","            17:'No entry',\n","            18:'General caution',\n","            19:'Dangerous curve left',\n","            20:'Dangerous curve right',\n","            21:'Double curve',\n","            22:'Bumpy road',\n","            23:'Slippery road',\n","            24:'Road narrows on the right',\n","            25:'Road work',\n","            26:'Traffic signals',\n","            27:'Pedestrians',\n","            28:'Children crossing',\n","            29:'Bicycles crossing',\n","            30:'Beware of ice/snow',\n","            31:'Wild animals crossing',\n","            32:'End speed + passing limits',\n","            33:'Turn right ahead',\n","            34:'Turn left ahead',\n","            35:'Ahead only',\n","            36:'Go straight or right',\n","            37:'Go straight or left',\n","            38:'Keep right',\n","            39:'Keep left',\n","            40:'Roundabout mandatory',\n","            41:'End of no passing',\n","            42:'End no passing veh > 3.5 tons' }"]},{"cell_type":"markdown","metadata":{"id":"dalweAJ0peUm"},"source":["Very important part. A loop that checks all the data inside the train folder and labels it correctly and stores everything in each list (data and labels) created before. 1 by 1 it resizes the image to 30x30 pixels so later we will have no problems when training the AI with these images."]},{"cell_type":"markdown","source":["# Data Processing\n"],"metadata":{"id":"VtjCYe1NIlQj"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"6tNyeSr2ZJyd"},"outputs":[],"source":["for i in range(classes):\n","    path = os.path.join(dataset_path, 'Train', str(i))\n","    images = os.listdir(path)\n","    for a in images:\n","        try:\n","            image = Image.open(os.path.join(path, a))\n","            image = image.resize((IMG_HEIGHT, IMG_WIDTH))\n","            image = np.array(image)\n","            data.append(image)\n","            labels.append(i)\n","        except Exception as e:\n","            print(e)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I6f6gaFHotHw"},"outputs":[],"source":["# Convertir listas a numpy arrays\n","data = np.array(data)\n","labels = np.array(labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CHSRENhOoBTQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715427437331,"user_tz":-120,"elapsed":14,"user":{"displayName":"Àlex Romero Segués","userId":"08771803099075012026"}},"outputId":"e17bfdeb-4ed4-40a0-a361-2e08a0eea980"},"outputs":[{"output_type":"stream","name":"stdout","text":["(39241, 30, 30, 3) (39241,)\n"]}],"source":["print(data.shape, labels.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kcOXc60Wnyn3"},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4zri1HG6uTFS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715427437722,"user_tz":-120,"elapsed":398,"user":{"displayName":"Àlex Romero Segués","userId":"08771803099075012026"}},"outputId":"c0deeb3e-5f3c-4a20-8fd7-b918cefaee6d"},"outputs":[{"output_type":"stream","name":"stdout","text":["(31392, 30, 30, 3) (7849, 30, 30, 3) (31392,) (7849,)\n"]}],"source":["print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u7zfWVHawr1J"},"outputs":[],"source":["y_train = to_categorical(y_train, 43)\n","y_test = to_categorical(y_test, 43)"]},{"cell_type":"markdown","metadata":{"id":"iKV1TEyzjcbU"},"source":["Splitting the data into train and validation set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WTHyKs384IIr"},"outputs":[],"source":["shuffle_indexes = np.arange(data.shape[0])\n","np.random.shuffle(shuffle_indexes)\n","data = data[shuffle_indexes]\n","labels = labels[shuffle_indexes]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f0UCUVZmjbf9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715427437983,"user_tz":-120,"elapsed":263,"user":{"displayName":"Àlex Romero Segués","userId":"08771803099075012026"}},"outputId":"91935200-a0e4-4831-95af-f25d83cbf5da"},"outputs":[{"output_type":"stream","name":"stdout","text":["Random:  5385\n","X_train.shape (27468, 30, 30, 3)\n","X_valid.shape (11773, 30, 30, 3)\n","y_train.shape (27468,)\n","y_valid.shape (11773,)\n"]}],"source":["random_state=random.randint(1,10000)\n","X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.3, random_state=42, shuffle=True)   #random.randint(1,10000)\n","\n","X_train = X_train/255\n","X_val = X_val/255\n","\n","print(\"Random: \", random_state)\n","print(\"X_train.shape\", X_train.shape)\n","print(\"X_valid.shape\", X_val.shape)\n","print(\"y_train.shape\", y_train.shape)\n","print(\"y_valid.shape\", y_val.shape)"]},{"cell_type":"markdown","metadata":{"id":"k0PDpqMhizco"},"source":["One hot encoding the labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zlRdShvpixgO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715427437984,"user_tz":-120,"elapsed":5,"user":{"displayName":"Àlex Romero Segués","userId":"08771803099075012026"}},"outputId":"9e0fa0ca-9d14-4348-ab53-9b19b7d99ebf"},"outputs":[{"output_type":"stream","name":"stdout","text":["(27468, 43)\n","(11773, 43)\n"]}],"source":["y_train = keras.utils.to_categorical(y_train, classes)\n","y_val = keras.utils.to_categorical(y_val, classes)\n","\n","print(y_train.shape)\n","print(y_val.shape)"]},{"cell_type":"markdown","metadata":{"id":"Mj6ZlUsdpaI3"},"source":["# Model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SdaTdvx4hCfJ"},"outputs":[],"source":["!pip install keras-tuner\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cv9XmXXKcDNw"},"outputs":[],"source":["aug = ImageDataGenerator(\n","    rotation_range=10,\n","    zoom_range=0.15,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    shear_range=0.15,\n","    horizontal_flip=False,\n","    vertical_flip=False,\n","    fill_mode=\"nearest\")\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MUGnJvl8likg"},"outputs":[],"source":["import kerastuner as kt\n","\n","def model_builder(hp):\n","\n","    model = keras.Sequential()\n","\n","    hp_filters1 = hp.Int('filters1', min_value=16, max_value=128, step=16)\n","    model.add(keras.layers.Conv2D(filters=hp_filters1, kernel_size=(3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, channels)))\n","\n","    hp_filters2 = hp.Int('filters2', min_value=32, max_value=256, step=32)\n","    model.add(keras.layers.Conv2D(filters=hp_filters2, kernel_size=(3, 3), activation='relu'))\n","\n","    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n","\n","    model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n","    model.add(keras.layers.BatchNormalization(axis=-1))\n","\n","    model.add(keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n","    model.add(keras.layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu'))\n","    model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n","    model.add(keras.layers.BatchNormalization(axis=-1))\n","    model.add(keras.layers.Flatten())\n","\n","    hp_units = hp.Int('units', min_value=256, max_value=1024, step=256)\n","    model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n","    model.add(keras.layers.BatchNormalization())\n","    model.add(keras.layers.Dropout(rate=0.5))\n","    model.add(keras.layers.Dense(43, activation='softmax'))\n","\n","    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n","                  loss='categorical_crossentropy',\n","                  metrics=['accuracy'])\n","\n","    return model\n","\n","\n","tuner = kt.Hyperband(model_builder,\n","                     objective='val_accuracy',\n","                     max_epochs=10,\n","\n","                     factor=3,\n","                     directory='my_dir',\n","                     project_name='traffic_sign_recognition')\n","\n","stop_early = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n","\n","tuner.search(aug.flow(X_train, y_train, batch_size=32),\n","             epochs=30,\n","             validation_data=(X_val, y_val),\n","             callbacks=[stop_early])\n","\n","best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n","\n","print(f\"The optimal number of filters in the first Conv2D layer is {best_hps.get('filters1')}\")\n","print(f\"The optimal number of filters in the second Conv2D layer is {best_hps.get('filters2')}\")\n","print(f\"The optimal learning rate for the optimizer is {best_hps.get('learning_rate')}\")\n","print(f\"The optimal number of units in the Dense layer is {best_hps.get('units')}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bNHjVKCoXl31"},"outputs":[],"source":["model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KXZVqOrZhgnx"},"outputs":[],"source":["model = tuner.hypermodel.build(best_hps)\n","history = model.fit(aug.flow(X_train, y_train, batch_size=32), epochs=30\n","                    , validation_data=(X_val, y_val))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dUHUspKWTUot"},"outputs":[],"source":["save_path = '/content/drive/MyDrive/TFG CODE/model.h5'\n","model.save(save_path)"]},{"cell_type":"markdown","metadata":{"id":"zcIGXW8IqdXA"},"source":["# Results\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5xF9x7D6mWXP"},"outputs":[],"source":["acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs_range = range(epochs)\n","\n","plt.figure(figsize=(10, 10))\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs_range, acc, label='Training Accuracy')\n","plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation Accuracy')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs_range, loss, label='Training Loss')\n","plt.plot(epochs_range, val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IYarc9REOqPz"},"outputs":[],"source":["test = pd.read_csv(dataset_path + '/Test.csv')\n","\n","labels = test[\"ClassId\"].values\n","imgs = test[\"Path\"].values\n","\n","data =[]\n","\n","for img in imgs:\n","    try:\n","        image = cv2.imread(data_dir + '/' +img)\n","        image_fromarray = Image.fromarray(image, 'RGB')\n","        resize_image = image_fromarray.resize((IMG_HEIGHT, IMG_WIDTH))\n","        data.append(np.array(resize_image))\n","    except:\n","        print(\"Error in \" + img)\n","X_test = np.array(data)\n","X_test = X_test/255\n","pred_probs = model.predict(X_test)\n","pred_classes = np.argmax(pred_probs, axis=1)\n","\n","#Accuracy with the test data\n","print('Test Data accuracy: ',accuracy_score(labels, pred_classes)*100)"]},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix\n","import seaborn as sns\n","from sklearn.metrics import classification_report\n","\n","cf = confusion_matrix(labels, pred)\n","df_cm = pd.DataFrame(cf, index = classes,  columns = classes)\n","plt.figure(figsize = (20,20))\n","# annot = True will display value associated with each cell\n","sns.heatmap(df_cm, annot=True)\n","\n","print(classification_report(labels, pred))"],"metadata":{"id":"b0X_ES51YAOR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P3IS0o1lruZa"},"source":["# New Images Tets\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ar58VN6lrxBt"},"outputs":[],"source":["Raw_images_path = '/content/drive/MyDrive/TFG CODE/Raw_Images/'\n","new_image = cv2.imread(Raw_images_path + '4.webp')\n","print(new_image.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eTsv-AiTnC84"},"outputs":[],"source":["plt.imshow(cv2.cvtColor(new_image, cv2.COLOR_BGR2RGB))\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RUQKM2chnJlC"},"outputs":[],"source":["gray_image = cv2.cvtColor(new_image, cv2.COLOR_BGR2GRAY)\n","plt.imshow(gray_image)\n","plt.show()\n","print(\"Shape: \",gray_image.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wYBT4U-AnLfY"},"outputs":[],"source":["blurred_image = cv2.GaussianBlur(gray_image, (5, 5), 0)\n","plt.imshow(blurred_image)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DRQcKmojmU3v"},"outputs":[],"source":["batch_size_new=1\n","channels_new=3\n","height_new=30\n","width_new=30\n","resized_image = cv2.resize(new_image, (width_new, height_new))\n","final_image = np.reshape(resized_image, (batch_size_new, height_new, width_new, channels_new))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K61AtCgMoR6t"},"outputs":[],"source":["print(\"Shape: \",final_image.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zbbPWhN7sTPU"},"outputs":[],"source":["predictions = model.predict(final_image)\n","print(predictions)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vJny0-9jHTZw"},"outputs":[],"source":["class_name, conf_score = classify(image, model, class_names)"]}],"metadata":{"colab":{"collapsed_sections":["JGsQE5slndXB","MhKHoXHQnn7A","LcTX2axypVdx","Mj6ZlUsdpaI3"],"provenance":[],"gpuType":"T4","mount_file_id":"1AXPq8A3C7JvUVWZUIgwBSQTATNVhU1Mp","authorship_tag":"ABX9TyPa7GTs0g1UPqj1ETvo22Nv"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}